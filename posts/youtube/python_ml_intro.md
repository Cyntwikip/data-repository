# tactiq.io free youtube transcript
# Python and Machine Learning for Beginners
# https://www.youtube.com/watch/OpASO4Q1lLA

00:01:00.193 Got him. Got it. 
00:09:27.867 and I threw it everyone and 
00:09:30.136 welcome for our first um 30 
00:09:32.705 days of ML talks and uh we are 
00:09:36.709 glad to have here. uh one of 
00:09:39.278 our speakers for today who 
00:09:41.747 would be teaching us Python and 
00:09:43.616 machine learning for beginners. 
00:09:45.584 So, before I 
00:10:18.951 sugar and um as science and 
00:10:22.121 data science at the university. 
00:10:24.590 Um so, let's uh do welcome our 
00:10:27.093 first speaker uh for today. Um 
00:10:30.496 Jude, Hello, Jude. Hello. Good 
00:10:34.300 afternoon. Thank you so much 
00:10:37.136 for um agreeing to speak and 
00:10:40.639 share your knowledge to our our 
00:10:42.742 dentist for today. Thank you 
00:10:45.243 for inviting me. Alright, are 
00:10:47.780 you are you are we going to 
00:10:48.814 start too? 
00:11:00.092 Yes. I think you can see it. 
00:11:01.594 Okay, let's start. So, and we 
00:11:05.731 do on my background because um 
00:11:08.166 I was already introduced but 
00:11:09.702 yeah, I am currently a engineer 
00:11:11.369 but uh previously, I work as a 
00:11:13.005 data scientist and IPTV and I'm 
00:11:16.208 currently a an assistant 
00:11:17.643 professor of lecture in the LSU 
00:11:19.078 and I took data science and 
00:11:21.080 computer science 
00:11:41.167 and I. can you see the chat? 
00:11:42.668 Would it be possible to see 
00:11:43.702 that 
00:11:50.142 Anyway, um so I go is um 
00:11:55.247 machine learning created by 
00:11:56.148 Google We're in. I was able to 
00:11:58.984 beat the top. the top globe 
00:12:00.786 there and um if you don't know, 
00:12:04.790 go as much more complicated 
00:12:06.759 than chess. So, um it is 
00:12:09.728 doesn't mean that there are um 
00:12:12.631 so many possibilities in this 
00:12:14.567 game that it exceeds the number 
00:12:15.700 of apps in the universe. That's 
00:12:17.236 how complicated this thing is 
00:12:18.771 and they're able to create a 
00:12:20.138 model that can be the top 
00:12:22.675 player in the game. So, this is 
00:12:24.743 really amazing. This is one of 
00:12:26.345 the um things with artificial 
00:12:30.115 intelligence or AI. and I've 
00:12:33.785 also seen this paragraph on the 
00:12:37.690 internet and I'll just read 
00:12:38.890 this for you. So, general 
00:12:40.960 artificial intelligence is 
00:12:42.861 going to happen a few years 
00:12:44.029 from now. There's now a 
00:12:44.897 reasonable amount of skepticism 
00:12:46.966 about whether AI will be an 
00:12:48.534 improvement on us at present 
00:12:50.035 It's ability to generalize the 
00:12:51.437 new situations is questionable. 
00:12:54.039 The challenges of language 
00:12:55.441 processing and scientific 
00:12:56.609 modeling are significant while 
00:12:58.711 ethical issues are formidable. 
00:13:00.613 However, it cleared that 
00:13:02.147 today's AI systems are 
00:13:03.549 progressing against fast paced 
00:13:05.217 and that their numerical 
00:13:08.153 capabilities are increasing. Um 
00:13:11.156 would you agree with this 
00:13:13.692 statement that I got from the 
00:13:15.261 enjoyment? Do you think 
00:13:16.228 generally, it's going to happen 
00:13:17.296 a few years from now 
00:13:46.759 Pretty cool. 
00:13:50.262 So, AI is very important 
00:13:53.132 nowadays and we are at the 
00:13:55.234 forefront of industry 4.00 
00:13:56.802 we're in. Um there's so many 
00:13:59.171 high tech Um we have a 
00:14:03.876 blockchain and other things but 
00:14:12.718 in an industrial revolution. Um 
00:14:14.353 there is a massive shift in how 
00:14:16.021 we live our lives. For example, 
00:14:18.157 back then, we are mainly 
00:14:20.626 focusing on agriculture. Then, 
00:14:22.227 we started to rely on. So a 
00:14:26.598 certain situation from um 
00:14:28.667 industry there, I guess and to 
00:14:30.336 industry 1.00 and then you get 
00:14:33.672 ideas. So 122.00 um we started 
00:14:38.043 to harness electricity and then 
00:14:40.879 our computers and for me it's 
00:14:42.247 the synergy of all these 
00:14:43.916 systems. so have this 
00:14:45.884 intelligent now Now, I'm one of 
00:14:48.988 the main psychology behind um 
00:14:52.658 the advancements in this for my 
00:14:55.060 Ai So, what is Ai Well, um 
00:15:00.732 generally speaking, um when we 
00:15:03.669 try to mimic human behavior and 
00:15:05.838 apply it to our computer 
00:15:07.072 systems, that is Ai so even if 
00:15:11.777 it's it's very simple task like 
00:15:15.114 um probably classify 
00:15:39.838 Oh one. So under AI. That is 
00:15:42.674 very hard nowadays is machine 
00:15:45.210 learning. So, machine learning. 
00:15:47.880 um it is um relies on data. So, 
00:15:52.750 we feed um the model with with 
00:15:54.820 lots and lots of data and The 
00:15:58.657 idea is that we'll be able to 
00:16:00.259 learn the pattern on its own. 
00:16:02.828 without us, it's um manually 
00:16:05.097 coding the rules. So, that's a 
00:16:07.266 bit of machine learning. We're 
00:16:09.701 learning is just a subset of 
00:16:12.037 machine learning specifically 
00:16:13.605 um neural networks. So, neural 
00:16:16.375 networks are loosely patterned 
00:16:18.510 after the human brain. It's not 
00:16:20.245 exactly how the human brain 
00:16:21.313 works but um that's the 
00:16:22.614 inspiration for it and it is 
00:16:26.485 the Core algorithm in many 
00:16:31.824 state of the art models that 
00:16:33.658 you'll see nowadays like um 
00:16:35.861 Cambridge classification, 
00:16:37.096 object detection, any other 
00:16:39.565 advanced um these cases, AI 
00:16:42.835 usually use the techniques or 
00:16:44.369 your metrics. So, to summarize 
00:16:46.738 AI is the bigger umbrella than 
00:16:50.109 inside of this machine learning 
00:16:51.143 the inside of the learning 
00:17:12.030 So, because you know, um we 
00:17:15.867 will sometimes uh portray that 
00:17:17.902 we can only achieve this using 
00:17:19.805 AI but in reality, we can't and 
00:17:22.241 after some time people will 
00:17:23.208 realize that um we can only get 
00:17:26.145 here at least right now. So, um 
00:17:28.680 that's where the um winter 
00:17:31.550 happens. So it happened back in 
00:17:33.652 1970s and in 1980s because 
00:17:35.721 there was a mismatch the 
00:17:36.955 expectations but recently um AI 
00:17:39.190 is booming because um of lots 
00:17:42.494 of attachments which we will 
00:17:44.696 discuss. So, first of all, we 
00:17:47.366 have data um and as I mentioned 
00:17:50.602 earlier, data is needed in 
00:17:53.071 machine learning models because 
00:17:54.706 what we're doing is we just 
00:17:55.941 need it with lots and lots of 
00:17:57.709 data and uh by doing that, it 
00:18:00.846 will um it um figure out the 
00:18:04.215 pattern on its own. So, because 
00:18:06.318 right now, we have so many 
00:18:07.753 data. um AI and ML is working 
00:18:12.958 and uh you've heard of this 
00:18:16.128 that the world's most valuable 
00:18:17.930 resources 
00:18:21.533 Let's go. So, it is projected 
00:18:23.869 that we'll have 175 a day by 
00:18:27.539 2025. Although this was 
00:18:28.707 conducted back in trade in the 
00:18:31.309 study, and uh what is that? 
00:18:35.080 Like how big is that? So, what 
00:18:36.047 is that about is 1 billion 
00:18:38.584 times 1 trillion. Very big 
00:18:40.619 hundred and again, as we have 
00:18:43.588 more data um machine learning 
00:18:45.524 models will let the um perform 
00:18:49.327 better than it was back then. 
00:18:51.296 They're feeling it more and 
00:18:52.130 more examples for to learn from 
00:18:56.335 So, that's the first thing we 
00:18:57.769 have. Be the second is hard. Um 
00:19:01.239 this is the more stuff. So, the 
00:19:03.442 more states that the number of 
00:19:05.577 ancestors on integrated 
00:19:07.412 circuits um doubles 
00:19:11.016 approximately every 2 years As 
00:19:13.986 you can see in this crowd. So, 
00:19:15.920 what does this mean for us? It 
00:19:18.056 means um we have more 
00:19:20.259 competition, more power in a 
00:19:21.693 single trip. It can perform so 
00:19:23.662 many calculations and of 
00:19:25.330 course, since we're using 
00:19:25.998 computers here, um you will 
00:19:28.399 benefit from that more 
00:19:29.835 complications faster, faster, 
00:19:33.505 more 
00:19:37.342 and um lastly, there's the 
00:19:38.710 research. There's the 
00:19:40.279 algorithms. I mean, if you have 
00:19:41.279 what you have, if you you have 
00:19:42.514 data you don't have algorithms, 
00:19:44.349 then it's a point. 
00:20:17.749 uh the time we're in, you know, 
00:20:19.584 are we getting a performance 
00:20:21.787 out of a new model that is 
00:20:23.621 quite good and it's also used 
00:20:26.625 um Gpu but it's not that 
00:20:29.661 popular um for VP but this is 
00:20:32.397 one of the earlier um 
00:20:34.666 researched use GPU So. Yeah and 
00:20:40.172 one of the authors here is the 
00:20:45.110 he's one of the godfather of 
00:20:46.745 the Jeffrey 
00:21:00.859 It's not just the Alex Smith. 
00:21:02.894 There's so many more that is 
00:21:04.529 important to do. So, these are 
00:21:06.031 the cons of AI. 
00:21:11.103 and Joshua Benjamin So, to 
00:21:14.206 summarize, um the cost of the 
00:21:16.708 PIE resurgence is the hardware 
00:21:19.177 and research 
00:21:23.115 So, some applications. So, 
00:21:24.816 you'll better appreciate AI and 
00:21:28.754 so um pay attention. It's one 
00:21:32.791 very popular use of a and it 
00:21:35.360 can get very high accuracy with 
00:21:38.429 this. Although there are ways 
00:21:40.232 to pull these systems but for 
00:21:44.402 the most part, um they're good 
00:21:50.575 an improvement that this is a 
00:21:51.843 collection. So, it's more 
00:21:53.245 complicated than face 
00:21:53.779 detection. So, you have to the 
00:21:57.215 objects in a in a video, 
00:21:58.950 they're just in an image Oh 
00:22:02.520 yeah. I created this back then. 
00:22:04.256 So, it's just this uh project 
00:22:07.225 that I have been using those 
00:22:09.628 things. So, for example, who's 
00:22:12.397 I like to do projects on the 
00:22:14.466 eye. So, yeah, it's it's a face 
00:22:17.268 of affection object detection, 
00:22:19.371 then some temperature scanner. 
00:22:21.506 So yeah, those are the things 
00:22:23.108 you could do with a um you can 
00:22:24.910 also do self-driving cars 
00:22:30.816 um clustering in 
00:22:32.184 identification. You can do that 
00:22:32.884 with Ai. 
00:22:45.530 This is what I use to generate 
00:22:47.098 that. So, for example, if you 
00:22:48.934 type something here, it will 
00:22:51.002 continue that. So, you can do 
00:22:52.170 that with the So, I will show 
00:22:59.644 you some um projects about the 
00:23:04.182 we. Can I share my screen for a 
00:23:06.751 bit? I'll open those 
00:23:43.355 a few seconds. 
00:24:00.539 Okay. here. So, 
00:24:08.613 For example, this one, let's 
00:24:11.683 try this one. 
00:25:15.046 So, it was able to identify the 
00:25:18.149 emotion of the person in that 
00:25:21.285 image. We'll see you then look 
00:25:25.824 for other emotions, objects, 
00:25:28.326 and glasses First person to 
00:25:30.127 person, top table, 
00:25:35.099 How about another example? So, 
00:25:37.636 how about a house? So, let's go 
00:25:40.338 to the fact that this is a 
00:25:41.206 house and yeah, the different 
00:25:43.374 objects in that image, Sorry, 
00:25:52.283 What? I upload my image. What 
00:25:54.252 will happen 
00:25:59.257 So, joy. a bit of joy and love 
00:26:03.595 for others. objects, and person 
00:26:06.397 and talk. Cool, right? So, um 
00:26:09.333 that's one of the things that 
00:26:10.634 you can do with AI. There's 
00:26:12.203 also this quick draw If you 
00:26:16.874 draw something, we'll, you 
00:26:18.042 know, that is. so the straw 
00:26:20.411 feather I see a line. Oh, I 
00:26:24.916 know it's feather feather. 
00:26:29.287 Skyline. I don't know. How do 
00:26:31.322 you go to Skyline? I'm not even 
00:26:32.457 sure. Let's just get this. I 
00:26:35.192 think it's hard. 
00:27:14.566 So, with that, um let us um 
00:27:18.236 proceed with the task force on 
00:27:20.271 them. So, you better appreciate 
00:27:22.040 it. So, how does Emma work? a 
00:27:25.110 machine learning is the bells 
00:27:27.779 to learn without being 
00:27:29.047 exquisitely programmed. So, we 
00:27:30.781 just be lots of examples and 
00:27:32.217 the to learn. For example, I 
00:27:34.853 show you this picture a picture 
00:27:36.721 of a what is this, What do you 
00:27:39.424 think Is this It is a picture 
00:27:41.859 of a cup. So, yeah, let me say 
00:27:43.494 that this is a cup. How about 
00:27:45.263 this one? 
00:27:51.136 Uh Um and then how about this 
00:27:54.939 one? This is I don't know, a 
00:27:58.710 silhouette. maybe a cat but How 
00:28:02.647 do we know that um those images 
00:28:05.850 are linked to these concepts 
00:28:08.153 like this image when you see 
00:28:09.721 it, I know that this is a cat 
00:28:11.756 and this one, I know that this 
00:28:13.291 is a dog. Why do you think 
00:28:15.660 that's the case? Um it is 
00:28:18.062 because we have seen so many 
00:28:21.166 examples of um these animals 
00:28:25.036 since we were born. So, it's 
00:28:27.739 the same thing for machine 
00:28:28.540 learning systems. You eat a lot 
00:28:30.041 of examples a baby. Um it's 
00:28:33.611 done at first but you uh but 
00:28:36.213 after giving so many examples, 
00:28:37.882 it will learn those things 
00:28:40.051 eventually. 
00:29:30.235 We um in machine learning, 
00:29:32.704 supervised machine learning. Um 
00:29:34.305 it's it's going to try to 
00:29:36.607 figure out this one in between 
00:29:39.410 whatever it is. The goal is to 
00:29:42.113 match the out with some 
00:29:45.550 transformation that we'll do it 
00:29:48.253 For example, This is my input 
00:29:52.456 and this is my output. What is 
00:29:54.525 this thing in between? The ML 
00:29:58.195 should figure that out for us 
00:30:00.131 but um this is a this is an 
00:30:02.667 easy example. So, we could 
00:30:05.370 actually figure out what this 
00:30:09.207 mathematical expression in The 
00:30:10.642 key is. It's very simple. So, 
00:30:12.343 it's just a multiplication 2.2 
00:30:16.848 Two times the input will become 
00:30:19.584 this. It's all about 
00:30:35.600 So, it's just like. so if you 
00:30:37.801 have this, you apply this um 
00:30:41.005 formula, you'll get this and in 
00:30:46.176 machine learning, we don't have 
00:30:48.312 to figure out those things. We 
00:30:53.051 just use a model and um the 
00:30:54.953 idea is that will learn that uh 
00:30:58.122 mapping for us input out of 
00:30:59.691 mapping. If you have an input, 
00:31:01.259 whatever it is, you have an 
00:31:02.560 output, it will try to map that 
00:31:06.698 so we could use lots of models 
00:31:09.266 for that. and you're not 
00:31:11.936 limited to the form that you 
00:31:15.139 were seeing in there just 
00:31:15.773 numbers. You can use an image 
00:31:17.241 because in reality, they're all 
00:31:19.143 numbers. So, if you need an 
00:31:21.112 image, you use a model and then 
00:31:23.781 it will predict that it's a dog 
00:31:25.149 or a cat or whatever is in that 
00:31:27.251 image. You can also text be it 
00:31:34.492 and then some ML model and then 
00:31:36.961 it will return it up. So, 
00:31:40.697 that's supervised machine 
00:31:42.066 learning. 
00:32:19.137 classification. Our goal is to 
00:32:21.706 classify our database and for 
00:32:24.675 example, um we have an uh maybe 
00:32:28.579 it's uh it's a problem where 
00:32:31.515 you have to identify the 
00:32:33.651 animals and that image. So, for 
00:32:35.753 example, of course, forbid or 
00:32:38.055 maybe you want to identify them 
00:32:41.626 sex of that person in image or 
00:32:44.394 whatever need that we have. So, 
00:32:45.997 it's male or female or a class 
00:32:47.432 or failed. So, that is 
00:32:48.666 classification. Basically, you 
00:32:50.601 are picking one of the many 
00:32:52.870 labels that you have that 
00:32:55.173 whereas in regression, you are 
00:32:56.507 predicting numerical values. 
00:32:59.110 So, an example that's like the 
00:33:00.577 two rates stock price or 
00:33:02.947 demand, those are regression 
00:33:04.515 examples. some more examples. 
00:33:08.820 progression. They offer this 
00:33:09.587 one. You're trying to protect 
00:33:12.723 the temperature based on the 
00:33:14.625 cricket chips per minute. So, 
00:33:16.694 based on of the specialization, 
00:33:18.596 you could easily see that there 
00:33:19.730 is a linear pattern. So, if uh 
00:33:23.701 the cricket trips were made it 
00:33:25.202 tight and we expect the 
00:33:28.106 temperature to be high as well. 
00:33:31.709 You can also protect them. our 
00:33:35.947 demand Um the system that we 
00:33:37.581 implement and visualization and 
00:33:39.784 hydro supplying graph for 
00:33:44.856 classification. Again, we're 
00:33:46.057 trying to classify the data 
00:33:49.160 points in our data center. So, 
00:33:53.164 this is the in this process. we 
00:33:55.766 have this and this is the end 
00:33:57.602 and you can see in this 
00:33:58.202 visualization that um those 
00:34:00.571 data points that have low um 
00:34:04.909 supplements with right here, 
00:34:06.144 there are more or less um this 
00:34:09.547 browns that we have here. What 
00:34:11.349 is this called? Orange. 
00:34:13.117 something blue. It's a 
00:34:15.652 different models will have 
00:34:16.987 different ways of classifying 
00:34:17.922 your data and this 
00:34:20.658 visualization is just to show 
00:34:21.458 you that um yeah, they have 
00:34:23.594 different types of doing it. 
00:34:24.762 So, um use the appropriate 
00:34:26.531 model for the data that you 
00:34:28.533 have So, there are many many 
00:34:31.902 models like there's naive days, 
00:34:35.572 neighbors which is the 
00:34:36.641 progression Sm to support their 
00:34:39.911 machines and our efforts, your 
00:34:42.880 networks is deep learning once 
00:34:44.547 again So, I'm just to give you 
00:34:47.685 an idea. So, this is what's 
00:34:50.855 does 
00:34:54.625 When you're trying to identify 
00:34:56.960 the classification of your new 
00:34:59.430 data point, you just look at 
00:35:01.065 your neighbors and that will be 
00:35:02.934 your classification. Very 
00:35:04.869 straightforward. 
00:35:16.714 So, eventually, this will 
00:35:19.383 become a line at least for this 
00:35:20.751 day for sale. this line will um 
00:35:25.723 have the minimum error in this 
00:35:28.059 particular day. 
00:35:34.165 So, you have, if you have um a 
00:35:38.236 problem that is uh linear then 
00:35:43.507 you might want to use the 
00:35:44.074 linear. just a regression Sm. 
00:35:47.278 If you're dealing with image 
00:35:48.245 data use on your network. So, 
00:35:51.349 yeah, basically, if you have um 
00:35:52.683 there are different algorithms 
00:35:53.451 for different problems. That's 
00:35:55.553 the point. you don't use single 
00:35:58.222 algorithm for all the problems 
00:35:59.624 that we have. It's case of this 
00:36:09.233 and if you need like a kite, 
00:36:10.868 then uh you can use the psychic 
00:36:14.538 cheat sheet for um using the 
00:36:18.576 molds depending on the problem 
00:36:21.379 that you have. For example, in 
00:36:22.747 here, if you have more than 
00:36:24.148 fifty samples, go here. Um if 
00:36:26.083 you're predicting a more you go 
00:36:28.118 here, you have a legal data 
00:36:29.420 here. Um that's one of the 
00:36:32.490 samples. He's here as we 
00:37:38.622 So, um there are lots of 
00:37:41.592 evaluation metrics that we 
00:37:43.227 could use um by default when 
00:37:45.763 you use um and we will do that 
00:37:48.699 and the hats on session um and 
00:37:51.702 default, it uses accuracy for a 
00:37:54.739 classification and R squared 
00:37:56.340 for progression tasks but um 
00:38:41.018 be safely. So, we have over 
00:38:43.154 fitting and underwriting. So, 
00:38:44.622 what are those? Um over fitting 
00:38:47.191 is basically um you memorizing 
00:38:48.892 the train set and performing 
00:38:51.362 for you on the person and the 
00:38:53.764 fitting is unable to model the 
00:38:55.299 train set and generalize the 
00:38:57.902 passive um and this 
00:39:00.604 visualization here you will see 
00:39:02.873 that on the left side, we have 
00:39:05.176 an unfit model. It's just a 
00:39:07.344 line but you can see it should 
00:39:09.113 be a curve. It should be AU 
00:39:10.448 shape 
00:39:21.625 It's not perfect but it was 
00:39:23.193 able to capture the trend. It's 
00:39:26.229 usually here 
00:39:32.369 It's like rooted for you are um 
00:39:35.705 trying your best to capture it 
00:39:37.241 all possible points but in 
00:39:39.643 reality, that's not like the 
00:39:40.511 pattern. You don't have that 
00:39:44.615 Sinus aid. wave function. So, 
00:39:49.687 it's a you with some sinuses in 
00:39:51.187 here. 
00:39:57.228 more examples of 150 and over 
00:39:59.797 fitting. So, if you have this 
00:40:01.332 data set, you just use the line 
00:40:03.934 to split it and the one in 
00:40:06.337 between is the best one. It's 
00:40:09.240 just okay. There are some mis 
00:40:10.975 classifications they can hear. 
00:40:12.142 There's to access inside like 
00:40:14.712 this. um area that should be 
00:40:17.180 for the circle but that's okay. 
00:40:20.117 and um on the right one, we 
00:40:21.618 have an over the model 
00:41:06.997 It's uh the weather forecast is 
00:41:09.533 an informative signal. Make 
00:41:11.468 sense, right? Then, we collect 
00:41:13.971 data And then we train them 
00:41:16.607 all. The reason that they and 
00:41:19.209 the reality is the results. 
00:41:21.245 It's a small, better than the 
00:41:22.646 existing systems that we have. 
00:41:24.648 If not, um maybe I should do 
00:41:27.518 that more to of the many things 
00:41:29.920 that we have. Um identified 
00:41:31.388 when we're doing the analysis 
00:41:33.090 and then lastly is um you you 
00:41:36.292 could refine your hypothesis 
00:41:37.895 and you could focus on the time 
00:41:39.496 of the year not the weather 
00:41:46.270 Another important thing is um 
00:41:48.639 framing your machine learning 
00:41:50.207 problem before you do all those 
00:41:51.909 models, you have to frame it 
00:41:54.311 properly if you have to as you 
00:41:56.713 have articulate your problem, 
00:41:58.482 see if there's a data for that 
00:42:00.718 design your data, you have to 
00:42:02.886 the processing for the model 
00:42:04.054 that you're using and so many 
00:42:06.357 more. 
00:42:10.027 So, this is the typical 
00:42:12.062 pipeline when doing a um with 
00:42:14.765 with the identification of 
00:42:16.166 framing. you construct or just 
00:42:18.168 get the if it's available 
00:42:19.837 already. you transform the day 
00:42:20.604 you train the model, then you 
00:42:22.640 check the performance or they 
00:42:24.307 will, this is the evaluation 
00:42:29.146 So, first thing you have to 
00:42:33.249 identify the type of problem 
00:42:35.219 that you you do it. You have 
00:42:40.257 seen this earlier already. So, 
00:42:42.092 if you're picking one up and 
00:42:43.661 labels, that's classification. 
00:42:45.195 If you're predicting the values 
00:42:46.830 of aggression. Uh this one is 
00:42:48.832 an extra here. This is actually 
00:42:50.834 for a supervised learning. So, 
00:42:52.603 if you want to give some 
00:42:53.604 examples that's clustering, 
00:42:58.642 and here are some examples. Why 
00:43:02.246 is this important? Because you 
00:43:03.914 have to use appropriate model. 
00:43:06.150 depending on the problem that 
00:43:07.518 you have. Um there are models 
00:43:09.186 for justification, and 
00:43:11.188 regression and questioning 
00:43:16.593 and uh please start with a 
00:43:19.496 simple bottle. You don't have 
00:43:20.831 to use um complicated ones when 
00:43:23.801 um you're just starting your 
00:43:27.037 model 
00:43:30.607 often good that you rely on 
00:43:33.477 tried and tested models because 
00:43:35.745 that is why they are popular 
00:43:38.048 and try to test it because they 
00:43:39.616 they work well even though if 
00:43:41.618 they're just simple, that's 
00:43:42.986 okay. At least you have a 
00:43:44.822 baseline and um usually the the 
00:43:47.758 biggest game in the in the ML 
00:43:48.559 is the first one. So yeah, just 
00:43:51.695 have a model running already. 
00:43:53.897 Don't spend too much time on 
00:43:56.200 optimizing it on using a very 
00:43:57.901 sophisticated ones. The 
00:43:59.670 simplest ones will at first. 
00:44:06.610 What else? Um we also do the 
00:44:10.547 analysis. This is really really 
00:44:12.182 important. because um this 
00:44:14.685 gives us a sense of what data 
00:44:17.187 we are dealing with before we 
00:44:20.390 do the right. It's it's really 
00:44:22.726 helpful if you know what you 
00:44:24.061 are playing with. So, perform 
00:44:26.797 some visualizations. Do all um 
00:44:29.700 do some statistics and whatnot 
00:44:32.236 so that you better know your 
00:44:34.137 data 
00:44:52.589 the descriptive stats that it 
00:44:55.125 um will give you are the same. 
00:44:58.028 If you try to like apply a 
00:45:00.864 linear model for this. this is 
00:45:02.332 what you will get and if check 
00:45:04.968 the descriptive stats, they're 
00:45:06.937 all the same for example. So, 
00:45:08.872 you can see different 
00:45:13.277 visualization, right? Very 
00:45:14.544 different data points but they 
00:45:17.247 all have the same descriptive 
00:45:18.615 statistics and that is why it 
00:45:20.250 is important that you for ED, 
00:45:22.686 visualize the first, see if it 
00:45:24.555 makes sense. 
00:45:28.692 You'll see. Let's see here. 
00:45:29.860 They have the same stats. 
00:45:31.995 They're not the same. 
00:45:59.223 um for model training. This is 
00:46:00.724 the simplest um code that you 
00:46:04.528 could use to run a model Of 
00:46:06.396 course. Uh if you're dealing 
00:46:08.632 with heart problems and you 
00:46:09.933 have to do more steps but um 
00:46:12.803 you could train in a evaluate 
00:46:16.139 the model with these three 
00:46:18.175 lines. This is the simplest 
00:46:20.343 example If you need more 
00:46:24.715 inspiration on your project, 
00:46:27.651 then you can look at there's so 
00:46:28.885 many projects there. There's 
00:46:30.621 also papers with code If you 
00:46:32.956 need to have lots of data sets 
00:46:34.257 are in cargo. There's also one 
00:46:36.326 in the world that can do the 
00:46:37.761 search for tutorials. There's 
00:46:39.930 so many on the internet. You 
00:46:41.131 just Google them. There's so 
00:46:43.100 many resources right now. Okay. 
00:46:46.937 Um I think we can proceed with 
00:46:49.072 the hats on session right now. 
00:46:51.074 Are there any questions? 
00:47:12.195 I think that would be best if 
00:47:13.664 you do this together with me, I 
00:47:16.199 will send you the link. How do 
00:47:18.268 I send it? 
00:47:28.545 Anyway, um 
00:47:36.219 So, 
00:47:39.690 Um for those of you who are not 
00:47:42.159 familiar with Python and about 
00:47:45.162 this is how you imports in 
00:47:48.699 Python and um these three 
00:47:50.801 libraries are very important in 
00:47:52.869 the data science and space 
00:47:54.271 figures They provide us the 
00:47:57.641 tools that we need to do pre 
00:47:59.176 processing table manipulations 
00:48:00.811 and visualizations. Um we call 
00:48:03.680 them the data science trio or 
00:48:05.882 trifecta 
00:48:34.077 I just want that. I have to be 
00:48:35.678 more pretty. 
00:48:39.850 So, um the biggest said that we 
00:48:41.384 will be using for the session 
00:48:43.854 is the Irish You've seen that 
00:48:46.023 they're here. So, we have three 
00:48:48.658 classes here. Is there one and 
00:48:50.293 two and they are one, two, and 
00:48:59.936 I have a free to remove this 
00:49:01.404 part but uh this part is just 
00:49:02.839 for loading the data things 
00:49:06.043 that you have to take note of. 
00:49:10.614 So, I have X and Y and black 
00:49:13.116 and white Contains X contains 
00:49:15.552 the input. So, this is our 
00:49:17.687 input. so many, right? So, I'm 
00:49:20.056 just going to 
00:49:30.567 That's the impact for Just 
00:49:33.403 showing the first five rows. in 
00:49:37.140 our data and why is this What 
00:49:42.112 this means is um the first five 
00:49:46.183 rows in our data are called 
00:49:48.051 zero 
00:49:52.155 Okay. Um next, we perform EDA 
00:49:56.226 or exploratory analysis. So, we 
00:50:00.764 look at some descriptive steps. 
00:50:05.168 for the different features that 
00:50:06.837 we have. So, we have four 
00:50:08.038 features. Um zero is one is a 
00:50:16.246 three and two is pedal pedal. 
00:50:20.517 That's I should have. So, I'll 
00:50:24.187 add the bones for you. 
00:51:13.103 It won't help explain all the 
00:51:15.272 lines because it will take up 
00:51:16.773 most of our time and they have 
00:51:19.309 so many people over here 
00:51:25.182 So, this is what our data looks 
00:51:26.650 like if we focus on the first 
00:51:28.451 two features. This is a scam. 
00:51:31.721 So, by looking at this, you 
00:51:34.724 could already see some 
00:51:36.126 clustering, some pattern like 
00:51:38.228 all the flowers are here. All 
00:51:42.298 the virgin are in here and all 
00:51:44.234 the versatile are in here. 
00:51:46.469 There's some powdered already 
00:51:47.370 that you can see So, it's 
00:51:50.440 important to do some 
00:51:51.741 visualization. It's also look 
00:51:53.643 at the distribution 
00:51:58.615 So, they have the same cats 
00:52:01.551 which If you have a brain and 
00:52:06.156 that will be problematic for 
00:52:07.457 your machinery and your model. 
00:52:08.658 If it's balanced, then we have 
00:52:11.094 no problems. 
00:52:23.240 class. Although this this 
00:52:26.109 visualization here already 
00:52:28.712 captures that somehow, this is 
00:52:31.248 just the one dimensional view 
00:52:33.583 of it. and the the one, we have 
00:52:36.419 two dimensions. So, you can do 
00:52:38.421 the same for other 
00:52:57.741 for the help with the the color 
00:53:02.612 has the highest and it's almost 
00:53:07.684 the same. 
00:53:18.662 We will be using Pascale 
00:53:20.563 Library for the modeling. 
00:53:54.364 first step that we will do but 
00:53:56.832 I have nothing but I'm sorry. I 
00:53:58.301 have not done the earlier like 
00:54:01.104 II. commented it out. It's this 
00:54:03.373 one. 
00:54:23.793 Um it splits the data into two. 
00:54:26.596 Remember, we have to have train 
00:54:28.898 and that training is for a 
00:54:31.000 training or model that that is 
00:54:33.269 for evaluate your model, the 
00:54:34.871 exam, you plug in X and Y the 
00:54:39.542 input. is the output that I 
00:54:44.347 controls the size of the 
00:54:46.583 vessel. So, since it's .2 or 
00:54:49.219 20% and that means that we will 
00:54:51.354 have 80% and that's right here 
00:54:54.957 is just for um disability 
00:54:57.860 purposes so that the output of 
00:55:00.330 this one will be consistent 
00:55:01.631 across all roads. So, this 
00:55:04.634 design is just an extra to make 
00:55:06.936 sure that everything is 
00:55:07.837 consistent If you want that 
00:55:11.274 part, you'll have three tests. 
00:55:14.144 So, therefore, out your you're 
00:55:19.616 input for the transit. That's 
00:55:22.185 that's the input for the white 
00:55:24.721 train. The output for the train 
00:55:26.923 set and whites, the output for 
00:55:30.059 the pass. 
00:55:33.463 and if you look at the values, 
00:55:35.598 they're consistent. So, 
00:55:37.200 initially, we have 150 year 
00:55:39.169 olds. If we split them, we have 
00:55:42.105 a train set size of 120 Since 
00:55:46.276 it's it's 50% of the data and 
00:55:48.978 for the test because it's 20% 
00:55:50.746 of the data 
00:56:40.096 Our hope is that those um 
00:56:42.699 classification for the back 
00:56:44.300 points here should match the 
00:56:46.703 one that we have earlier 
00:56:48.104 because this is the true 
00:56:50.773 classification So, if you do 
00:56:53.676 not include them, what will be 
00:56:54.911 their classification now? So, 
00:56:56.412 they will be like the exam and 
00:56:59.949 we study for all these data 
00:57:02.318 that we have here. 
00:57:14.664 So, for now, we will be using 
00:57:16.132 the Key Neighbors Pacifier 
00:57:18.133 model. So, this is how we do it 
00:57:20.837 in. So, it's just import it and 
00:57:24.908 then we initially the model, 
00:57:27.143 you can actually remove this by 
00:57:31.714 default. It will have some 
00:57:34.584 parameters in there. but I just 
00:57:36.886 want to show you that these are 
00:57:38.187 some of the parameters that you 
00:57:39.522 could configure when um so this 
00:57:43.793 one I'm doing um the industry 
00:57:47.130 and the initial of your gay 
00:57:50.600 neighbors, our model 
00:59:15.618 If you want to see the other 
00:59:17.253 metrics recession, we call it 
00:59:19.355 from Again, that's visualize 
00:59:24.093 our predictions. 
00:59:28.264 So, this is the graph. Um we 
00:59:32.368 have Um the the point here is 
00:59:36.139 the one. This is the but after 
00:59:40.109 um predicting their class based 
00:59:42.044 on the model that we have 
00:59:43.913 trained. You can see um that 
00:59:45.815 that I have colored them based 
00:59:48.384 on the classification that they 
00:59:50.053 have and it's consistent with 
00:59:52.388 the ones that we have right 
00:59:54.090 here. We have a very good model 
01:00:09.105 So, um I've already uploaded 
01:00:11.741 the data for you. Um this data 
01:00:15.011 set contains um the subject of 
01:00:21.250 the Emails that were sent to 
01:00:22.618 different users and um the 
01:00:26.122 associated labels for them. for 
01:00:27.689 those who he is for not spam 
01:00:30.426 and spam for spam. So, So, this 
01:00:33.229 the distribution in our day We 
01:00:37.800 have lots of not spams for him 
01:00:42.105 and um a few. Well, not that 
01:00:46.174 you but almost half of the um 
01:00:51.214 counts of the hands or stamps. 
01:00:53.649 So, I think this is already a 
01:00:55.318 good enough distribution. I 
01:00:57.820 won't perform other people 
01:00:59.122 except for the penalty part 
01:01:01.758 here. I won't explain that the 
01:01:04.861 end of part because it is out 
01:01:06.362 of scope of this course button. 
01:01:12.769 but first, um we will be 
01:01:14.137 splitting the day, right? 
01:01:15.538 That's the first thing. So, we 
01:01:16.773 have our training and 
01:01:52.708 So, now that it has been 
01:01:54.210 transformed in the format, that 
01:01:56.779 can be understood that our 
01:01:59.115 models, we will be doing the 
01:01:59.982 model. So, let's use the 
01:02:02.184 logistic regression. another 
01:02:03.953 machine learning model 
01:02:08.157 stuff. We the model. This is 
01:02:13.362 this part and then we train the 
01:02:15.765 model. and then we check this 
01:02:20.203 part of the train set. So, very 
01:02:21.670 high. Of course, it's a train 
01:02:23.138 set but what about the Tessa? 
01:02:25.408 We're still getting very high 
01:02:27.610 results. 
01:02:31.147 You're perfect. 
01:02:34.717 So, to further break it down so 
01:02:36.219 that you believe that it's 
01:02:39.288 working as expected. I've 
01:02:41.724 identified the uh some of the 
01:02:45.261 roles that our hams and spams. 
01:02:47.696 So, these are the not spam 
01:02:50.233 Emails and let's look at the 
01:02:55.104 facts inside that. It's quite 
01:02:58.908 long so I can show all of it. 
01:03:02.478 Uh 
01:03:06.682 if you want to see it, you 
01:03:14.090 Listen. 
01:03:17.159 So, 
01:03:18.127 this is the subject. Um all 
01:03:22.331 of these Emails are not spam 
01:03:30.640 If we predicted using our model 
01:03:33.042 that we have trained earlier, 
01:03:34.710 you can see that it was able to 
01:03:36.512 predict it correctly. There are 
01:03:38.213 not really 
01:03:44.620 about the prime examples. 
01:03:52.061 I or something. 
01:03:59.669 Uh anyway, this one. Yeah. It's 
01:04:03.806 one that's probably so these 
01:04:05.841 are the spam Emails and yeah, 
01:04:08.711 when these are modeled um it 
01:04:11.447 was able to classify them 
01:04:13.683 correctly that they're all 
01:04:15.217 spam. So, yeah, that is the 
01:04:19.922 basics of Ml. won't go to the 
01:04:22.224 aggression here because I think 
01:04:23.025 we're out of time. That's what 
01:04:24.493 I do but it should be the same 
01:04:26.995 thing. It's the same process. 
01:04:30.132 you um initially the model you 
01:04:32.535 train it, you evaluate it. 
01:04:36.072 Basically, this one. 
01:04:40.009 with these three lines, you can 
01:04:41.944 now train and evaluate your 
01:04:44.079 model. 
01:04:47.016 Any 
01:04:48.117 questions? 
01:04:52.588 Okay. Uh there's a question. 
01:04:54.090 What does labeled data mean? It 
01:04:56.025 means that 
01:05:29.725 You just have the Emails. So, 
01:05:32.228 what do we do with that? No 
01:05:35.498 idea you could maybe before 
01:05:37.733 clustering. That's where I'm 
01:05:39.201 at. But yeah, that is this is 
01:05:42.037 an example of a day. 
01:07:40.156 Okay. So, um first question 
01:07:42.624 here is after what you have 
01:07:44.326 learned in this session, how 
01:07:45.661 would you describe it? 
01:07:49.064 in three 
01:07:49.364 words. 
01:08:09.018 still no 
01:08:30.538 Yeah. 
01:08:38.781 Yeah. it. can be complicated 
01:08:42.350 depending on the on. Yeah. 
01:09:14.750 with this at a high level. 
01:09:29.098 That's for you. responses. 
01:09:46.615 Okay, great. 
01:09:50.185 the next. So, what average 
01:09:55.858 Three 
01:10:15.544 No. None. 
01:10:19.715 That's a day. Yes, it's really 
01:10:20.683 important. 
01:10:32.661 What are those? 
01:10:38.233 It is the future. Yeah, I 
01:10:39.902 agree. 
01:10:49.244 It's the training. That's it. 
01:10:51.313 Yeah. 
01:10:54.983 good responses. Thank you. We 
01:10:58.487 have another question. 
01:11:03.592 I think that's the last one. 
01:11:07.830 Okay, last one. Where do you 
01:11:10.466 want to know a guy? 
01:11:24.813 So, thank you. Okay. 
01:11:31.887 There's some right 
01:11:50.172 Okay, great. Thank you for 
01:11:52.040 that. Yeah. Orange juice. 
01:12:15.631 Adrian. Thank you so much for 
01:12:17.298 your uh for joining us. I think 
01:12:19.601 um are there things that you 
01:12:22.070 would want to share especially 
01:12:23.772 with those who are listening to 
01:12:26.008 us to know more about learning 
01:12:28.577 uh with resources that are 
01:12:30.345 helpful for them if they're 
01:12:31.780 planning to start their journey 
01:12:33.215 towards um building projects 
01:12:36.351 and machine learning Um 
01:12:41.290 II sugges
01:12:41.590 t having good 
01:12:44.359 foundations. we still need the 
01:12:45.627 mats um but also um try to 
01:12:49.131 apply them whenever you can. 
01:12:50.666 They come to a pet project. 
01:12:52.334 Something that you're really 
01:12:53.936 fascinated in. Try to use um 
01:12:57.072 what you have learned. You 
01:12:58.707 know, it's just a basic uh 
01:13:00.342 project At least you can apply 
01:13:02.945 what you've learned and it will 
01:13:04.346 reinforce your right and um the 
01:13:06.849 maybe after that you will um 
01:13:09.618 explore more complicated 
01:13:11.319 models, more sophisticated 
01:13:13.255 techniques because at least now 
01:13:14.055 you have the basics so that 
01:13:15.824 you're just doing Lots of 
01:13:17.793 personal projects and have a 
01:13:20.229 good foundations for the 
01:13:22.764 resources. I am such a We'll be 
01:13:28.237 starting with um an 
01:13:30.639 introductory course for and 
01:13:32.241 machine learning. That's where 
01:13:33.742 I started back then but after 
01:13:36.078 that, uh please read the books. 
01:13:39.081 um because there are so many 
01:13:41.149 content out there that you 
01:13:43.151 know, it's hard to figure out 
01:13:45.821 which ones to make sense which 
01:13:47.523 ones are really relevant. 
01:13:49.224 There's so many tutorials. 
01:13:50.826 There are so many articles. Um 
01:13:52.226 there are times actually when 
01:13:53.762 uh I've seen that they do not 
01:14:59.328 Yeah. Thank you so much. Thank 
01:15:01.630 you. Thank you. Have a great 
01:15:03.599 day. 
